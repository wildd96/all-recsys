{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a6164808-2b20-4d30-8f2a-3922335e7519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is a starting point\n",
    "#uncomment below to install merlin library\n",
    "#!pip install merlin, nvtabular, merlin.models\n",
    "#I had to downgrade keras to 12.2.0 there maybe issues regarding tensorflow in the future\n",
    "#run lines below if you have also have an error ab not finding a keras package\n",
    "\n",
    "#!pip uninstall keras\n",
    "#!pip install keras==2.12.0\n",
    "\n",
    "\n",
    "#These are the same imports from\n",
    "#https://github.com/NVIDIA-Merlin/models/blob/main/examples/02-Merlin-Models-and-NVTabular-integration.ipynb\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import nvtabular as nvt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from merlin.models.utils.example_utils import workflow_fit_transform\n",
    "import merlin.io\n",
    "import tensorflow\n",
    "\n",
    "import merlin.models.tf as mm\n",
    "from merlin.io.dataset import Dataset\n",
    "from nvtabular.ops import *\n",
    "from merlin.core.utils import download_file\n",
    "from merlin.schema.tags import Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a340cdef-e86d-43fe-ac78-a6ff62a25aed",
   "metadata": {},
   "source": [
    "# Load and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6dd79ec9-f741-4e0d-a46e-123e36c4f68c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/merlin/io/parquet.py:343: UserWarning: Row group memory size (1648670318) (bytes) of parquet file is bigger than requested part_size (1073741824) for the NVTabular dataset.A row group memory size of 128 MB is generally recommended. You can find info on how to set the row group size of parquet files in https://nvidia-merlin.github.io/NVTabular/main/resources/troubleshooting.html#setting-the-row-group-size-for-the-parquet-files\n",
      "  warnings.warn(\n",
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#num rows\n",
    "data_size = df.shape[0]\n",
    "\n",
    "#We're doing a 20/80 train/validate split change the .2 to change the split\n",
    "train_split_ratio = int(.2 * data_size)\n",
    "\n",
    "train_data = df[train_split_ratio:].to_parquet(\"train_data.parquet\")\n",
    "valid_data = df[:train_split_ratio].to_parquet(\"valid_data.parquet\")\n",
    "\n",
    "train = Dataset(\"train_data.parquet\")\n",
    "valid = Dataset(\"valid_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b424279-225c-4eef-b583-0427bc954c57",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95493f8f-f037-4bc2-b737-3e3cb0c14967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/andrew/Desktop/projects/recsys_data/2023-10-05 9_23pm.csv') \n",
    "#  ^ This needs point to your local .csv too big for github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "032fb1a0-26b4-42c1-a348-b103f9d80e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accidentally added an extra CLICKSTREAM_EVENTS_TOTAL column\n",
    "df = df.drop(columns = ['CLICKSTREAM_EVENTS_TOTAL.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770badc5-5a3d-4282-a455-fef1eff25209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc862f-90f9-4db2-858b-bc4e93925ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da5efa1f-91e7-4c32-a882-6bbe6fe26555",
   "metadata": {},
   "source": [
    "# NVTabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f247a55-cbdd-4cce-8b47-7e939e0984e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is how to iniate a dataset using NVtabular an NVIDIA \n",
    "#optimized ETL/feature engineering(i think?) library\n",
    "#data = nvt.io.dataset.Dataset('data/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c65d68b7-27c7-436e-9d49-58c91cc067fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d3c6c8f-282a-489f-8e5c-51411edc1435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_user_features = ['COUNTRY', 'DERIVED_GENDER_BY_NAME', 'EVENT_NAME']\n",
    "categorical_item_features = ['STYLE', 'TAXONOMY_STYLE', 'COLOR_NAME', 'PRODUCT_CLASS', 'PRODUCT_SUBCLASS', 'TEAM', 'FRANCHISE', 'PRODUCT_GROUP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f941f6d0-41be-4177-aac5-a884aa7bb630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Features needed to Transform still: FIRST_PURCHASE_AT, FIRST_VISIT_AT, LATEST_VISIT_AT\n",
    "# LATEST_PURCHASE_AT, EVENT_TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c397eb73-c1bc-4e1b-838c-d72a85c2adb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#DON'T FORGET TARGET ENCODING CATEGORICAL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74895def-f932-4e9c-b1f8-0d78da2b7571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_id = [\"USER_ID\"] >> Categorify(dtype = \"int32\") >> FillMissing(0) >> TagAsUserID()\n",
    "item_id = [\"ITEM_ID\"] >> Categorify(dtype = \"int32\") >> FillMissing(0)  >> TagAsItemID()\n",
    "item_features = categorical_item_features >> Categorify(dtype = \"int32\") >> FillMissing(0)  >> TagAsItemFeatures()\n",
    "user_features = categorical_user_features >> Categorify(dtype = \"int32\") >> FillMissing(0)  >> TagAsUserFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8fe5b8c4-f25e-4429-94b5-4d807f212134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Node TagAsUserFeatures output>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9d3d475a-df44-4291-bbd7-1f534e8d5c34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Make this more succinct\n",
    "CLICKSTREAM_EVENTS_TOTAL = (\n",
    "    ['CLICKSTREAM_EVENTS_TOTAL']\n",
    "    >>FillMissing(0)\n",
    "    >>LogOp()\n",
    "    >>Normalize()\n",
    "    >>LambdaOp(lambda col: col.astype(\"float32\"))\n",
    "    >>TagAsUserFeatures()\n",
    ")\n",
    "\n",
    "#has the price changed over time?\n",
    "PRICE_INFORMATION = (\n",
    "    ['PRICE_INFORMATION']\n",
    "    >>FillMissing(0)\n",
    "    >>LogOp()\n",
    "    >>Normalize()\n",
    "    >>LambdaOp(lambda col: col.astype(\"float32\"))\n",
    "    >>TagAsItemFeatures()\n",
    ")\n",
    "\n",
    "AVG_REVIEW_SCORE = (\n",
    "    ['AVG_REVIEW_SCORE']\n",
    "    >>FillMissing(0)\n",
    "    >>LogOp()\n",
    "    >>Normalize()\n",
    "    >>LambdaOp(lambda col: col.astype(\"float32\"))\n",
    "    >>TagAsItemFeatures()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "19e65950-c396-4a0c-be31-65adaaa63418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = (\n",
    "    user_id + \n",
    "    user_features + \n",
    "    CLICKSTREAM_EVENTS_TOTAL + \n",
    "    item_id +\n",
    "    item_features + \n",
    "    PRICE_INFORMATION +\n",
    "    AVG_REVIEW_SCORE\n",
    ")\n",
    "\n",
    "workflow = nvt.Workflow(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5261238e-74f6-42ab-b059-62ff5cd24f25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/merlin/io/parquet.py:343: UserWarning: Row group memory size (1648670318) (bytes) of parquet file is bigger than requested part_size (1073741824) for the NVTabular dataset.A row group memory size of 128 MB is generally recommended. You can find info on how to set the row group size of parquet files in https://nvidia-merlin.github.io/NVTabular/main/resources/troubleshooting.html#setting-the-row-group-size-for-the-parquet-files\n",
      "  warnings.warn(\n",
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 s, sys: 3.89 s, total: 24.7 s\n",
      "Wall time: 24.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:402: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_data = Dataset('train_data.parquet') #Direct to your local files\n",
    "valid_data = Dataset('valid_data.parquet')\n",
    "\n",
    "workflow.fit_transform(train_data).to_parquet(\n",
    "    'train_data_transformed' #Feel free to replace with your own local file path\n",
    ")\n",
    "workflow.transform(valid_data).to_parquet(\n",
    "    'valid_data_transformed' #same here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bcd359-0fbc-4ac2-b660-23d57e375134",
   "metadata": {},
   "source": [
    "## Transform Timestamped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e3470a1c-4786-4ccd-a592-395036db4286",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "/Users/andrew/anaconda3/lib/python3.11/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_transformed = Dataset('train_data_transformed', engine = 'parquet')\n",
    "valid_transformed = Dataset('valid_data_transformed', engine = 'parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7c6271c3-6eff-47c2-9759-120c352e6cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>DERIVED_GENDER_BY_NAME</th>\n",
       "      <th>EVENT_NAME</th>\n",
       "      <th>CLICKSTREAM_EVENTS_TOTAL</th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>STYLE</th>\n",
       "      <th>TAXONOMY_STYLE</th>\n",
       "      <th>COLOR_NAME</th>\n",
       "      <th>PRODUCT_CLASS</th>\n",
       "      <th>PRODUCT_SUBCLASS</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>FRANCHISE</th>\n",
       "      <th>PRODUCT_GROUP</th>\n",
       "      <th>PRICE_INFORMATION</th>\n",
       "      <th>AVG_REVIEW_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70320</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.264287</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.277768</td>\n",
       "      <td>0.857715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>691</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.861603</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.411870</td>\n",
       "      <td>-0.824569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1471</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.420414</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.803233</td>\n",
       "      <td>0.585295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>580</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.473524</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.544698</td>\n",
       "      <td>0.415922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27946</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.584007</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.445158</td>\n",
       "      <td>0.339810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USER_ID  COUNTRY  DERIVED_GENDER_BY_NAME  EVENT_NAME  \\\n",
       "0    70320        1                       1           3   \n",
       "1      691        3                       3           3   \n",
       "2     1471        3                       3           3   \n",
       "3      580        3                       3           3   \n",
       "4    27946        3                       3           3   \n",
       "\n",
       "   CLICKSTREAM_EVENTS_TOTAL  ITEM_ID  STYLE  TAXONOMY_STYLE  COLOR_NAME  \\\n",
       "0                 -1.264287       16      3               3          20   \n",
       "1                  1.861603       48     11               8          29   \n",
       "2                  1.420414       25     12              10          25   \n",
       "3                  0.473524        7      4               4           6   \n",
       "4                 -0.584007        9      6               7           5   \n",
       "\n",
       "   PRODUCT_CLASS  PRODUCT_SUBCLASS  TEAM  FRANCHISE  PRODUCT_GROUP  \\\n",
       "0              3                 4     3          4              3   \n",
       "1              3                 3     4          9              4   \n",
       "2              3                 4     3          5              4   \n",
       "3              3                 3     4          3              3   \n",
       "4              3                 5     5          6              3   \n",
       "\n",
       "   PRICE_INFORMATION  AVG_REVIEW_SCORE  \n",
       "0           0.277768          0.857715  \n",
       "1           0.411870         -0.824569  \n",
       "2           0.803233          0.585295  \n",
       "3           0.544698          0.415922  \n",
       "4          -0.445158          0.339810  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "056922d0-f08a-43d7-9bf7-182c20d57086",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m mm\u001b[38;5;241m.\u001b[39mDLRMModel(\n\u001b[1;32m      2\u001b[0m     train_transformed\u001b[38;5;241m.\u001b[39mschema,\n\u001b[1;32m      3\u001b[0m     embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      4\u001b[0m     bottom_block\u001b[38;5;241m=\u001b[39mmm\u001b[38;5;241m.\u001b[39mMLPBlock([\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m]),\n\u001b[1;32m      5\u001b[0m     top_block\u001b[38;5;241m=\u001b[39mmm\u001b[38;5;241m.\u001b[39mMLPBlock([\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m32\u001b[39m]),\n\u001b[1;32m      6\u001b[0m     prediction_tasks\u001b[38;5;241m=\u001b[39mmm\u001b[38;5;241m.\u001b[39mBinaryOutput(\n\u001b[0;32m----> 7\u001b[0m         train_transformed\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mselect_by_tag(Tags\u001b[38;5;241m.\u001b[39mTARGET)\u001b[38;5;241m.\u001b[39mcolumn_names[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m     ),\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_transformed, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model = mm.DLRMModel(\n",
    "    train_transformed.schema,\n",
    "    embedding_dim=64,\n",
    "    bottom_block=mm.MLPBlock([128, 64]),\n",
    "    top_block=mm.MLPBlock([128, 64, 32]),\n",
    "    prediction_tasks=mm.BinaryOutput(\n",
    "        train_transformed.schema.select_by_tag(Tags.TARGET).column_names[0]\n",
    "    ),\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\")\n",
    "model.fit(train_transformed, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a4afd-1d11-4390-809f-107476ec31e7",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7a91203f-c19f-4e46-addf-33ea46aa544e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<merlin.io.dataset.Dataset at 0x301fd04d0>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "79d329a2-d750-4f71-8f28-78d33414a716",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Binary classification task requires a column with a ', '`Tags.BINARY_CLASSIFICATION` tag.')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m mm\u001b[38;5;241m.\u001b[39mDLRMModel(\n\u001b[1;32m      2\u001b[0m     train_transformed\u001b[38;5;241m.\u001b[39mschema,                                                   \u001b[38;5;66;03m# 1\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      4\u001b[0m     bottom_block\u001b[38;5;241m=\u001b[39mmm\u001b[38;5;241m.\u001b[39mMLPBlock([\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m]),                            \u001b[38;5;66;03m# 2\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     top_block\u001b[38;5;241m=\u001b[39mmm\u001b[38;5;241m.\u001b[39mMLPBlock([\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m32\u001b[39m]),\n\u001b[0;32m----> 6\u001b[0m     prediction_tasks\u001b[38;5;241m=\u001b[39mmm\u001b[38;5;241m.\u001b[39mBinaryClassificationTask(train\u001b[38;5;241m.\u001b[39mschema)      \u001b[38;5;66;03m# 3\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madagrad\u001b[39m\u001b[38;5;124m\"\u001b[39m, run_eagerly\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train, validation_data\u001b[38;5;241m=\u001b[39mvalid, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/merlin/models/tf/prediction_tasks/classification.py:69\u001b[0m, in \u001b[0;36mBinaryClassificationTask.__init__\u001b[0;34m(self, target, task_name, task_block, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m target_name \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mselect_by_tag(Tags\u001b[38;5;241m.\u001b[39mBINARY_CLASSIFICATION)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m target_name\u001b[38;5;241m.\u001b[39mcolumn_names:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinary classification task requires a column with a \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Tags.BINARY_CLASSIFICATION` tag.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     72\u001b[0m     )\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target_name\u001b[38;5;241m.\u001b[39mcolumn_names) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBinary classification task requires a single column with a \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Tags.BINARY_CLASSIFICATION` tag. \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m columns. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(target_name\u001b[38;5;241m.\u001b[39mcolumn_names)),\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease specify the column name with the `target` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     79\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: ('Binary classification task requires a column with a ', '`Tags.BINARY_CLASSIFICATION` tag.')"
     ]
    }
   ],
   "source": [
    "model = mm.DLRMModel(\n",
    "    train_transformed.schema,\n",
    "    embedding_dim=64,\n",
    "    bottom_block=mm.MLPBlock([128, 64]),\n",
    "    top_block=mm.MLPBlock([128, 64, 32]),\n",
    "    prediction_tasks=mm.BinaryClassificationTask(train.schema)\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adagrad\", run_eagerly=False)\n",
    "model.fit(train, validation_data=valid, batch_size=1024)\n",
    "eval_metrics = model.evaluate(valid, batch_size=1024, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cedc2fe-7756-4f09-8e26-4d6f2a9278ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
